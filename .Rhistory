?par
set.seed(2022)
par(mar = rep(0.2, 4))
data_Matrix <- matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(data_Matrix)[, nrow(data_Matrix):1]) #random stuff
#creating a heatmap:
?heatmap
?rep
par(mar = rep = (0.2, 4))
par(mar = rep(0.2, 4))
heatmap(data_Matrix)
for(i in 1:40){
# flipping a coin and getting the data
coin_Flip <- rbinom(1, size = 1, prob = 0.5)
# if the coin is "Heads", add a common pattern to that row,
if(coin_Flip){
data_Matrix[i, ] <- data_Matrix[i, ] + rep(c(0,3), each =5)
}
}
set.seed(2022)
set.seed(678910)
for(i in 1:40){
# flipping a coin and getting the data
coin_Flip <- rbinom(1, size = 1, prob = 0.5)
# if the coin is "Heads", add a common pattern to that row,
if(coin_Flip){
data_Matrix[i, ] <- data_Matrix[i, ] + rep(c(0,3), each =5)
}
}
# what I did here is, I looped through all the rows and, on a random row, I flipped a coin.
# during the coin flip, if is it turn out to be one (true), then, just added a pattern to my data in a way that the five of the columns have a mean of zero and others have mean of three.
#new heatmap:
heatmap(data_Matrix)
require(kknn)
data(ionosphere)
ionosphere.learn <- ionosphere[1:200,]
ionosphere.valid <- ionosphere[-c(1:200),]
fit.kknn <- kknn(class ~ ., ionosphere.learn, ionosphere.valid)
table(ionosphere.valid$class, fit.kknn$fit)
(fit.train1 <- train.kknn(class ~ ., ionosphere.learn, kmax = 15,
kernel = c("triangular", "rectangular", "epanechnikov", "optimal"), distance = 1))
table(predict(fit.train1, ionosphere.valid), ionosphere.valid$class)
(fit.train2 <- train.kknn(class ~ ., ionosphere.learn, kmax = 15,
kernel = c("triangular", "rectangular", "epanechnikov", "optimal"), distance = 2))
table(predict(fit.train2, ionosphere.valid), ionosphere.valid$class)
source('C:/Users/ajeet/Downloads/lab1_kknn2.R', echo=TRUE)
source('C:/Users/ajeet/Downloads/lab1_kknn2.R', echo=TRUE)
source('C:/Users/ajeet/Downloads/lab1_kknn3.R', echo=TRUE)
source('C:/Users/ajeet/Desktop/CSCI-4600/DataAnalytics2022_AjeetParmar/Lab3/lab1_bronx2.R', echo=TRUE)
source('C:/Users/ajeet/Desktop/CSCI-4600/DataAnalytics2022_AjeetParmar/Lab3/lab1_bronx2.R', echo=TRUE)
source('C:/Users/ajeet/Desktop/CSCI-4600/DataAnalytics2022_AjeetParmar/Lab3/lab1_bronx2.R', echo=TRUE)
source('C:/Users/ajeet/Desktop/CSCI-4600/DataAnalytics2022_AjeetParmar/Lab3/lab1_bronx2.R', echo=TRUE)
adduse<-adduse[!is.na(adduse$Latitude),]
mapcoord<-adduse[,c(2,3,24,25)]
addsample<-bronxadd[sample.int(dim(bronxadd),size=nsample),]#I use nval here
library(gdata)
rpart(Survived ~ ., Titanic)
library(rpart)
data(Titanic)
# rpart, ctree, hclust for:
#   Survived ~ .
rpart(Survived ~ ., Titanic)
ctree(Survived ~ ., Titanic)
source('C:/Users/ajeet/Desktop/CSCI-4600/DataAnalytics2022_AjeetParmar/Lab3/Lab3.R', echo=TRUE)
library(rpart)
library(partykit)
data(Titanic)
# rpart, ctree, hclust for:
#   Survived ~ .
rpart(Survived ~ ., Titanic)
ctree(Survived ~ ., Titanic)
CTree(Survived ~ ., Titanic)
source('C:/Users/ajeet/Desktop/CSCI-4600/DataAnalytics2022_AjeetParmar/Lab3/Lab3.R', echo=TRUE)
hclust(dist(Titanic))
library(ISLR)
heat(Hitters)
dim(Hitters)
is.na(Hitters)
df <- na.omit(Hitters)
dim(df)
head(df)
lmpredict <- lm(Salary ~., data = df)
summary(lmpredict)
Cd <- cooks.distance(lmpredict)
influential <- cd[cd > 3*mean(cd, na.rm = TRUE)]
#Implementing Cook's distance
cd <- cooks.distance(lmpredict)
influential <- cd[cd > 3*mean(cd, na.rm = TRUE)]
influential
summary(lmpredict1)
lmpredict1 <- lm(Salary ~ ., data = df1)
summary(lmpredict1)
df1 <- df %>% anti_join(outliers)
#model without outliers
lmpredict1 <- lm(Salary ~ ., data = df1)
summary(lmpredict1)
df1 <- df %>% anti_join(outliers)
#model without outliers
lmpredict1 <- lm(Salary ~ ., data = df1)
summary(lmpredict1)
df1 <- df %>% anti_join(outliers)
#model without outliers
lmpredict1 <- lm(Salary ~ ., data = df1)
summary(lmpredict1)
library(dplyr)
df1 <- df %>% anti_join(outliers)
#model without outliers
lmpredict1 <- lm(Salary ~ ., data = df1)
summary(lmpredict1)
library(ISLR)
library(dplyr)
heat(Hitters)
dim(Hitters)
is.na(Hitters)
df <- na.omit(Hitters)
dim(df)
head(df)
lmpredict <- lm(Salary ~., data = df)
summary(lmpredict)
#Implementing Cook's distance
cd <- cooks.distance(lmpredict)
influential <- cd[cd > 3*mean(cd, na.rm = TRUE)]
influential
outliers <- df[names(influential), ]
df1 <- df %>% anti_join(outliers)
#model without outliers
lmpredict1 <- lm(Salary ~ ., data = df1)
summary(lmpredict1)
setwd("C:/Users/ajeet/Desktop/research_landslides")
library(tidyverse)
library(dplyr)
library(readxl)
library(glmnet)
library(reshape2)
library(ggplot2)
library(rpart)
# reads in dataset pertaining to Californian power plants
dataset <- read.csv("California_Power_Plants.csv", header = TRUE, row.names=NULL)
head(dataset)
# reads in dataset pertaining to Californian power plants
power_plant_dataset <- read.csv("California_Power_Plants.csv", header = TRUE, row.names=NULL)
#check the class of the dataset columns
sapply(power_plant_dataset, class)
#changing column names from X and Y to Longitude and Latitude respectively
colnames(power_plant_dataset)[0] <- "Longitude"
colnames(power_plant_dataset)[1] <- "Latitude"
head(dataset)
head(power_plant_dataset)
head(power_plant_dataset)
library(tidyverse)
library(dplyr)
library(readxl)
library(glmnet)
library(reshape2)
library(ggplot2)
library(rpart)
# reads in dataset pertaining to Californian power plants
power_plant_dataset <- read.csv("California_Power_Plants.csv", header = TRUE, row.names=NULL)
#check if we read in the data properly
head(power_plant_dataset)
#check the class of the dataset columns
sapply(power_plant_dataset, class)
#changing column names from X and Y to Longitude and Latitude respectively
colnames(power_plant_dataset)[1] <- "Longitude"
colnames(power_plant_dataset)[2] <- "Latitude"
head(power_plant_dataset)
colnames(power_plant_dataset)[0]
#reads in power monthly
power_dataset <- read.csv("POWER_Regional_Monthly_2000_2020.csv", header = TRUE, row.names=NULL, skip = 11)
head(power_dataset)
#reads in power monthly
power_dataset <- read.csv("POWER_Regional_Monthly_2000_2020.csv", header = TRUE, row.names=NULL, skip = 10)
head(power_dataset)
colnames(power_plant_dataset)[4] <- "Longitude"
colnames(power_plant_dataset)[3] <- "Latitude"
source("C:/Users/ajeet/Desktop/research_landslides/data_cohesion.R", echo=TRUE)
#check if we read in the data properly
head(power_dataset)
#check if we read in the data properly
head(power_plant)dataset)
#check if we read in the data properly
head(power_plant_dataset)
# reads in solar radiation data
solar_radiation_dataset <- read.csv("Solar_Radiation_Data.csv", header = TRUE, row.names=NULL)
#check if we read in the data properly
head(solar_radiation_dataset)
#changing column names from lat and lon to Latitude and Longitude respectively
colnames(solar_radiation_dataset)[3] <- "Longitude"
colnames(solar_radiation_dataset)[2] <- "Latitude"
#check if we read in the data properly
head(solar_radiation_dataset)
#binding power plant dataset and monthly power dataset by longitude and latitude
temp <- rbind(power_plant_dataset, power_dataset)
#binding power plant dataset and monthly power dataset by longitude and latitude
temp <- merge(power_plant_dataset, power_dataset, solar_radiation_dataset, by = c("longitude", "latitude"))
df2 <- power_plant_dataset %>% inner_join( power_dataset,
by=c('Longitude','Latitude'))
head(df2)
# df2 <- power_plant_dataset %>% inner_join( power_dataset,
#                                            by=c('Longitude','Latitude'))
temp <- merge(power_plant_dataset, power_dataset, solar_radiation_dataset, by = c("Longitude", "Latitude"))
df2 <- power_plant_dataset %>% inner_join( power_dataset,
by=c('Longitude','Latitude'))
df2
df2 <- power_plant_dataset %>% merge( power_dataset,
by=c('Longitude','Latitude'))
df2
#check if we read in the data properly
head(power_plant_dataset)
